#Program 1
class Graph:
    def __init__(self,adjac_list):
        self.adjac_list=adjac_list
    
    def get_neighbors(self,v):
        return self.adjac_list[v]
    
    #heuristic function
    def h(self,n):
        H={
            'A':1,
            'B':1,
            'C':1,
            'D':1
        }
        return H[n]
    
    def a_star_algorithm(self,start,stop):
        open_lst=set([start])
        closed_lst=set([])
        dist={}
        dist[start]=0
        prenode={}
        prenode[start]=start
        
        while len(open_lst)>0:
            n=None
            
            for v in open_lst:
                if n==None or dist[v]+self.h(v)<dist[n]+self.h(n):
                    n=v
                    
            if n==None:
                print('Path does not exist')
                return None
            
            if n==stop:
                reconst_path=[]
                while prenode[n]!=n:
                    reconst_path.append(n)
                    n=prenode[n]
                    
                reconst_path.append(start)
                reconst_path.reverse()
                print('Path found: {}'.format(reconst_path))
                return reconst_path
            
            for (m,weight) in self.get_neighbors(n):
                if m not in open_lst and m not in closed_lst:
                    open_lst.add(m)
                    prenode[m]=n
                    dist[m]=dist[n]+weight
                    
                else:
                    if dist[m]>dist[n]+weight:
                        dist[m]=dist[n]+weight
                        prenode[m]=n
                        
                        if m in closed_lst:
                            closed_lst.remove(m)
                            open_lst.add(m)
                            
            open_lst.remove(n)
            closed_lst.add(n)
            
        print('Path does not exist!')
        return None
adjac_list={
    'A': [('B',1), ('C',3), ('D',7)],
    'B': [('D',5)],
    'C': [('D',12)]
    }

graph1=Graph(adjac_list)
graph1.a_star_algorithm('A', 'D')







#Program 2
def recAOStar(n):
    global finalPath
    print("Expanding Node : ", n)
    and_nodes = []
    or_nodes = []
    if (n in allNodes):
        if 'AND' in allNodes[n]:
            and_nodes = allNodes[n]['AND']
        if 'OR' in allNodes[n]:
            or_nodes = allNodes[n]['OR']
    if len(and_nodes) == 0 and len(or_nodes) == 0:
        return
    solvable = False
    marked = {}
    while not solvable:
        if len(marked) == len(and_nodes) + len(or_nodes):
            min_cost_least, min_cost_group_least = least_cost_group(and_nodes, or_nodes, {})
            solvable = True
            change_heuristic(n,min_cost_least)
            optimal_child_group[n] = min_cost_group_least
            continue
        min_cost, min_cost_group = least_cost_group(and_nodes, or_nodes, marked)
        is_expanded = False
        if len(min_cost_group) > 1:
            if (min_cost_group[0] in allNodes):
                is_expanded = True
                recAOStar(min_cost_group[0])
            if (min_cost_group[1] in allNodes):
                is_expanded = True
                recAOStar(min_cost_group[1])
        else:
            if (min_cost_group in allNodes):
                is_expanded = True
                recAOStar(min_cost_group)
        if is_expanded:
            min_cost_verify, min_cost_group_verify = least_cost_group(and_nodes, or_nodes, {})
            if min_cost_group == min_cost_group_verify:
                solvable = True
                change_heuristic(n, min_cost_verify)
                optimal_child_group[n] = min_cost_group
        else:
            solvable = True
            change_heuristic(n, min_cost)
            optimal_child_group[n] = min_cost_group
        marked[min_cost_group] = 1
    return heuristic(n)
    
def least_cost_group(and_nodes, or_nodes, marked):
    node_wise_cost = {}
    for node_pair in and_nodes:
        if not node_pair[0] + node_pair[1] in marked:
            cost = 0
            cost = cost + heuristic(node_pair[0]) + heuristic(node_pair[1]) + 2
            node_wise_cost[node_pair[0] + node_pair[1]] = cost
    for node in or_nodes:
        if not node in marked:
            cost = 0
            cost = cost + heuristic(node) + 1
            node_wise_cost[node] = cost
    min_cost = 999999
    min_cost_group = None

    for costKey in node_wise_cost:
        if node_wise_cost[costKey] < min_cost:
            min_cost = node_wise_cost[costKey]
            min_cost_group = costKey
    return [min_cost, min_cost_group]

def heuristic(n):
    return H_dist[n]

def change_heuristic(n, cost):
    H_dist[n] = cost
    return

def print_path(node):
    print(optimal_child_group[node], end="")
    node = optimal_child_group[node]

    if len(node) > 1:
        if node[0] in optimal_child_group:
            print("->", end="")
            print_path(node[0])
        if node[1] in optimal_child_group:
            print("->", end="")
            print_path(node[1])
    else:
        if node in optimal_child_group:
            print("->", end="")
            print_path(node)

H_dist = {
'A': -1,
'B': 4,
'C': 2,
'D': 3,
'E': 6,
'F': 8,
'G': 2,
'H': 0,
'I': 0,
'J': 0
}
allNodes = {
'A': {'AND': [('C', 'D')], 'OR': ['B']},
'B': {'OR': ['E', 'F']},
'C': {'OR': ['G'], 'AND': [('H', 'I')]},
'D': {'OR': ['J']}
}
optimal_child_group = {}
optimal_cost = recAOStar('A')
print('Nodes which gives optimal cost are')
print_path('A')
print('\nOptimal Cost is :: ', optimal_cost)








#Program 3
import csv
with open("Enjoysport.csv") as f:
    csv_file=csv.reader(f)
    data=list(csv_file)
    print("data",data)
    s=data[0][:-1]
    print("s",s)
    
    g=[['?' for i in range(len(s))] for j in range(len(s))]
    print("g",g)
    for i in data:
        if i[-1]=="yes":
            for j in range(len(s)):
                if i[j]!=s[j]:
                    s[j]='?'
                    g[j][j]='?'

        elif i[-1]=="no":
            for j in range(len(s)):
                if i[j]!=s[j]:
                    g[j][j]=s[j]
                else:
                    g[j][j]="?"

        print("\nStep " + str(data.index(i)+1))
        print(s)
        print(g)
    gh=[]
    for i in g:
        for j in i:
            if j!='?':
                gh.append(i)
                break
    print("\nFinal specific hypothesis:\n",s)
    print("\nFinal general hypothesis:\n",gh)







#Program 4
import numpy as np
import pandas as pd

eps=np.finfo(float).eps

from numpy import log2 as log

outlook='overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')
temp='hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')
humidity='high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')
windy='FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')
play='yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')
dataset={'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}
df=pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])
#print(df)

def find_entropy(df):
    Class=df.keys()[-1]
    entropy=0
    values=df[Class].unique()
    for value in values:
        fraction=df[Class].value_counts()[value]/len(df[Class])
        entropy+=-fraction*np.log2(fraction)
    return entropy

def find_entropy_attribute(df,attribute):
    Class = df.keys()[-1] #To make the code generic, changing target variable class name
    target_variables = df[Class].unique() #This gives all 'Yes' and 'No'
    variables = df[attribute].unique() #This gives different features in that attribute (like 'Hot','Cold' in Temperature)
    entropy2 = 0
    
    for variable in variables:
        entropy = 0
        for target_variable in target_variables:
            num = len(df[attribute][df[attribute]==variable][df[Class]==target_variable])
            den = len(df[attribute][df[attribute]==variable])
            fraction = num/(den+eps)
            entropy += -fraction*log(fraction+eps)
        fraction2 = den/len(df)
        entropy2 += -fraction2*entropy
    return abs(entropy2)

def find_winner(df):
    Entropy_att=[]
    IG=[]
    for key in df.keys()[:-1]:
        Entropy_att.append(find_entropy_attribute(df, key))
        IG.append(find_entropy(df)-find_entropy_attribute(df, key))
    return df.keys()[:-1][np.argmax(IG)]

def get_subtable(df,node,value):
    return df[df[node]==value].reset_index(drop=True)

def buildTree(df,tree=None):
    Class=df.keys()[-1]
    node=find_winner(df)
    attValue=np.unique(df[node])
    
    if tree is None:
        tree={}
        tree[node]={}
        
    for value in attValue:
        subtable=get_subtable(df, node, value)  
        clValue,counts=np.unique(subtable['play'],return_counts=True)
        
        if len(counts)==1:
            tree[node][value]=clValue[0]
        else:
            tree[node][value]=buildTree(subtable)
    return tree

t=buildTree(df)

import pprint
pprint.pprint(t)







#Program 5
import numpy as np
X=np.array(([2,9],[1,5],[3,6]),dtype=float)
y=np.array(([92],[86],[89]), dtype=float)
X=X/np.amax(X,axis=0)
y=y/100

#Sigmoid
def sigmoid(x):
    return 1/(1+np.exp(-x))

def derivatives_sigmoid(x):
    return x*(1-x)

#variable initialization
epoch=7000
lr=0.1
inputlayer_neurons=2
hiddenlayer_neurons=3
output_neurons=1

wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))
bh=np.random.uniform(size=(1,hiddenlayer_neurons))
wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))
bout=np.random.uniform(size=(1,output_neurons))

for i in range(epoch):
    #Forward
    hinp1=np.dot(X,wh)
    hinp=hinp1+bh
    hlayer_act=sigmoid(hinp)
    outinp1=np.dot(hlayer_act, wout)
    outinp=outinp1+bout
    output=sigmoid(outinp)
    
    #Backward
    EO=y-output
    outgrad=derivatives_sigmoid(output)
    d_output=EO*outgrad
    EH=d_output.dot(wout.T)
    hiddengrad=derivatives_sigmoid(hlayer_act)
    d_hiddenlayer=EH*hiddengrad
    wout+=hlayer_act.T.dot(d_output)*lr
    wh+=X.T.dot(d_hiddenlayer)*lr
    
print("Input: \n" + str(X))
print("Actual Output: \n" + str(y))
print("Predicted Output: \n" ,output)






#Program 6
import numpy as np
import pandas as pd

mush = pd.read_csv("mushroom.csv")
mush.replace('?', np.nan,inplace=True)
print(len(mush.columns),"columns, after dropping NA,", len(mush.dropna(axis=1).columns))

mush.dropna(axis=1,inplace=True)
target = 'class'
features = mush.columns[mush.columns!=target]
classes = mush[target].unique()
test = mush.sample(frac=0.3)
mush = mush.drop(test.index)
probs = {}
probcl = {}

for x in classes:
    mushcl = mush[mush[target]==x][features]
    clsp = {}
    tot = len(mushcl)
    for col in mushcl.columns:
        colp = {}
        for val,cnt in mushcl[col].value_counts().iteritems():
            pr=cnt/tot
            colp[val]=pr
            clsp[col]=colp
        
    probs[x]=clsp
    probcl[x]=len(mushcl)/len(mush)
    
def probabs(x):
    if not isinstance(x, pd.Series):
        raise IOError("Arg must of type Series")
    probab = {}
    
    for cl in classes:
        pr=probcl[cl]
        for col, val in x.iteritems():
            try:
                pr*=probs[cl][col][val]
            except KeyError:
                pr=0
        probab[cl]=pr
    return probab

def classify(x):
    probab=probabs(x)
    mx=0
    mxcl=''
    for cl,pr in probab.items():
        if pr > mx:
            mx=pr
            mxcl=cl
    return mxcl

b=[]
for i in mush.index:
    b.append(classify(mush.loc[i,features])==mush.loc[i,target])

print(sum(b),"correct of",len(mush))
print("Accuracy:", sum(b)/len(mush))

b=[]
for i in test.index:
    b.append(classify(test.loc[i,features])==test.loc[i,target])

print(sum(b),"correct of", len(test))
print("Accuracy:",sum(b)/len(test))








#Program 7
from copy import deepcopy
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans

data = pd.read_csv('ex.csv')
print("Input Data and Shape")
print(data.shape)
data.head()
print(data.head())

f1=data['V1'].values
print("f1")
print(f1)
f2=data['V2'].values
X=np.array(list(zip(f1,f2)))
print("X")
print(X)
print('Graph for whole dataset')
plt.scatter(f1,f2,c='black', s=600)
plt.show()

kmeans = KMeans(2,random_state=0)
labels = kmeans.fit(X).predict(X)
print("Labels")
print(labels)
centroids = kmeans.cluster_centers_
print("Centroids")
print(centroids)
plt.scatter(X[:,0], X[:,1], c=labels, s=40)
print('Graph using KMeans Algorithm')
plt.scatter(centroids[:,0],centroids[:,1],marker='*',s=200,c='#050505')
plt.show()

gmm = GaussianMixture(n_components=2).fit(X)
labels=gmm.predict(X)
print("1LABELS GMM")
print(labels)
probs = gmm.predict_proba(X)
size = 10*probs.max(1) ** 3
print('Graph using EM Algorithm')

plt.scatter(X[:,0], X[:,1], c=labels,s=size, cmap='viridis');
plt.show()








#Program 8
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
import numpy as np
from sklearn.model_selection import train_test_split

iris_dataset=load_iris()
'''print("\n IRIS FEATURES \ TARGET NAMES: \n", iris_dataset.target_names)
for i in range(len(iris_dataset.target_names)):
    print("\n[{0}]:[{1}]".format(i, iris_dataset.target_names[i]))

print("\n IRIS DATA :\n", iris_dataset["data"])'''

X_train, X_test, y_train, y_test = train_test_split(iris_dataset["data"], iris_dataset["target"], random_state=0)

'''print("\n Target :\n",iris_dataset["target"])
print("\n X TRAIN \n",X_train)
print("\n X TEST \n",X_test)
print("\n Y TRAIN \n",y_test)
print("\n Y TEST \n",y_test)
'''
kn = KNeighborsClassifier(n_neighbors=1)
kn.fit(X_train, y_train)

for i in range(len(X_test)):
    x = X_test[i]
    x_new = np.array([x])
    prediction = kn.predict(x_new)
    #print("\n Actual : {0} {1}, Predicted :{2}{3}".format(y_test[i], iris_dataset["target_names"][y_test[i]], prediction,iris_dataset["target_names"][prediction]))
    
print("\n TEST SCORE[ACCURACY]: {:.2f}\n".format(kn.score(X_test, y_test)))









#Program 9
from numpy import *
import matplotlib.pyplot as plt
import pandas as pd
from numpy.linalg import *

def kernel(point, xmat, k):
    m,n = shape(xmat)
    weights = mat(eye(m))
    for j in range(m):
        diff = point - X[j]
        weights[j,j] = exp(diff*diff.T/(-2.0*k**2))
    return weights

def localWeight(point, xmat, ymat, k):
    wei = kernel(point, xmat, k)
    W = (X.T*(wei*X)).I*(X.T*(wei*ymat.T))
    return W

def localWeightRegression(xmat,ymat,k):
    m,n = shape(xmat)
    ypred = zeros(m)
    for i in range(m):
        ypred[i] = xmat[i]*localWeight(xmat[i], xmat, ymat, k)
    return ypred

data = pd.read_csv('tips.csv')
bill = array(data.total_bill)
tip = array(data.tip)

mbill = mat(bill)
mtip = mat(tip)
m = shape(mbill)[1]
one = mat(ones(m))
X = hstack((one.T, mbill.T))

ypred = localWeightRegression(X, mtip, 10)
SortIndex = X[:,1].argsort(0)
xsort = X[SortIndex][:,0]
fig = plt.figure()

ax = fig.add_subplot(1,1,1)
ax.scatter(bill,tip,color='green')
ax.plot(xsort[:,1],ypred[SortIndex],color='red',linewidth=5)
plt.xlabel('Total bill')
plt.ylabel('Tip')
plt.show();
